<p><a name=top> </a>&nbsp;</p>
<p align=center>
    <a
    href="/README.md#top"><img
    src="https://img.shields.io/badge/Home-%23ff5733?style=for-the-badge&logo=home&logoColor=white"></a> <a
    href="/docs/syllabus.md#top"><img
    src="https://img.shields.io/badge/Syllabus-%230055ff?style=for-the-badge&logo=openai&logoColor=white"></a> <a
    href="https://docs.google.com/spreadsheets/d/1Jlx-BBsvVqmWhW1L9Fz6u18vPSjGXj1i/edit?usp=sharing&ouid=110996670184359055145&rtpof=true&sd=true"><img
    src="https://img.shields.io/badge/Groups-%23ffd700?style=for-the-badge&logo=users&logoColor=white"></a> <a
    href="https://moodle-courses2425.wolfware.ncsu.edu/course/view.php?id=7150"><img
    src="https://img.shields.io/badge/Moodle-%23dc143c?style=for-the-badge&logo=moodle&logoColor=white"></a> <a
    href="https://discord.gg/whDXzJGP"><img
    src="https://img.shields.io/badge/Discord-%23008080?style=for-the-badge&logo=discord&logoColor=white"></a> <a
    href="https://ncsu.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx?folderID=958aa5e8-f99e-441f-a545-b26400dfe515"><img
    src="https://img.shields.io/badge/Videos-%23ffa500?style=for-the-badge&logo=youtube&logoColor=white"></a> <a
    href="/LICENSE.md"><img
    src="https://img.shields.io/badge/(c)%20Tim%20Menzies,%202025-%234b4b4b?style=for-the-badge&logoColor=white"></a>
    <br>&nbsp;<br>
    <img width=200 src="/img/banner2.png">
</p>
<h1 align="center">:cyclone:&nbsp;CSC510: Software Engineering<br>NC&nbsp;State, Spring&nbsp;'25</h1>
      



Our notes here come from [Software Carpentary](https://swcarpentry.github.io/make-novice/index.html) notes
and the amazing [MIT missing semester](https://missing.csail.mit.edu/2020/metaprogramming/)
subject. 


As such, we share their copyright:
[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://github.com/idleberg/Creative-Commons-Markdown/blob/main/4.0/by-nc-sa.markdown),


## Introduction


Make is a tool which can run commands to read files, process these files in some way, and write out the processed files. For example, in software development, Make is used to compile source code into executable programs or libraries, but Make can also be used to:


- run analysis scripts on raw data files to get data files that summarize the raw data;
- run visualization scripts on data files to produce plots; and to
-  parse and combine text files and plots to create papers.
- record, in an executable form, all your short cuts 


Make is called a build tool - it builds data files, plots, papers, programs or libraries. It can also update existing files if desired.


Make tracks the dependencies between the files it creates and the files used to create these. If one of the original files (e.g. a data file) is changed, then Make knows to recreate, or update, the files that depend upon this file (e.g. a plot).


Make was first released in April 1977 by Stuart Feldman at Bell Labs. That makes it nearly 50 years old—but it's still widely used since:


- **Ubiquity & Stability** – *Make is deeply embedded in Unix-based systems, well-documented, and universally supported.*
- **Minimal Overhead** – *Newer tools (CMake, Ninja, Bazel) can be heavier, requiring extra dependencies or complex setup.*
- **Declarative & Efficient** – *It tracks dependencies automatically, only rebuilding what's necessary, without overengineering.*
- **Works Everywhere** – *Unlike newer tools, Make runs on virtually any system without special installation or configuration.*


Make was  motivated by a need for tool to automate software compilation dependencies—a problem that was becoming more complex as projects grew. The Make work laid the foundation for modern build automation and dependency management.


That said, if you're dealing with massive parallel builds, cross-platform projects, or non-C/C++ languages, newer tools might be a better fit. e.g.


- **CMake** – Meta-build system that generates Makefiles or Ninja files, common for C/C++.  
- **Ninja** – Fast, minimal build system, often used with CMake.  
- **Meson** – Simpler, faster alternative to CMake, optimized for performance.  
- **Bazel** – Scalable build tool from Google, great for large, multi-language projects.  
- **Gradle** (Java/Kotlin) – Powerful build automation, used for Android development.  
- **Cargo** (Rust) – Rust’s built-in build system and package manager.  
- **Maven** (Java) – Dependency management and build tool for Java applications.  
- **SBT** (Scala/Java) – Optimized for Scala, supports parallel execution.  
- **Just** – Modern, simple task runner, like Make but with cleaner syntax.  
- **Taskfile** – YAML-based task runner, popular in the Go ecosystem.  
- **Rake** (Ruby) – Ruby’s Make-like tool for automation and builds.  
- **Leiningen** (Clojure) –  manages dependencies and tasks.


## Key Makefile Concepts
A Makefile consists of **rules**, **targets**, **dependencies**, and **commands**. The basic structure is:


```
target: dependencies
	command
```


- **target**: The output file or action.
- **dependencies**: Files required to produce the target.
- **command**: The shell command to generate the target.


By default, Make runs a `Makefile` of commands in the local directory (but this can be reset using make -f file.mk).


Example


```make
updata.txt: data.txt
   echo "uping..."
   gawk '{print toupper($$0)}' data.txt > updata.txt
```


> Note that
all command lines _**must**_ start with a tab.
Aso, `$$` is the Make variable that returns `$`
    (so `$$0` is the gawk variable `$0` 
     but `$(SHELL)` is a make variable


Run with:


```sh
make updata.txt
```


In this example?


```
Makefiles are traditionally used for compiling code, but they can
also be powerful tools for automating data-driven workflows. This
tutorial focuses on using make alongside gawk, grep, and sed to
process data efficiently.
```


is processed and saved eslwhere as


```
MAKEFILES ARE TRADITIONALLY USED FOR COMPILING CODE, BUT THEY CAN
ALSO BE POWERFUL TOOLS FOR AUTOMATING DATA-DRIVEN WORKFLOWS. THIS
TUTORIAL FOCUSES ON USING MAKE ALONGSIDE GAWK, GREP, AND SED TO
PROCESS DATA EFFICIENTLY.
```
Note that the commands are only run on the dependencies are new than than the target.


- So if we run this twice, we only see the echo once.


```sh
$ make -s updata.txt
uping...


$ make -s  updata.txt
$
```


    
>  Note that `make -s` siences verbose output. Don't use it during debugging (when youw ant to see those errors)


### Automatic Variables


Make provides several automatic variables that simplify rule definitions:


- `$@` - The target filename.
- `$<` - The first prerequisite (dependency).
- `$^` - All prerequisites.


Example:


```make
%.uppercase: %
	gawk '{print toupper($0)}' $< > $@
```


Run:


```sh
make file.txt.uppercase
```


### Wildcard and Pattern Matching


```make
DATAFILES := $(wildcard dataset/*.txt)
PROCESSED := $(patsubst dataset/%, processed/%, $(DATAFILES))


processed/%.txt: dataset/%.txt
	gawk '{print toupper($0)}' $< > $@
```


### Functions in Makefiles


```make
EXT = txt
FILES = $(wildcard *.$(EXT))


print_files:
	@echo $(FILES)
```


### Self-Documenting Makefiles


```make
.PHONY: help
help : Makefile ## print help
	echo ""; printf "usage: make [OPTIONS]\n\n"
	@gawk 'BEGIN {FS="[ \t]*:.*##[ \t]*"}  \
	  NF==2 { printf \
           "  \033[36m%-25s\033[0m %s\n","make " $$1,$$2}'  $< \
	| grep -v awk
```


@: run without echoding line
\: used to continue previous line.
   - Pro-tip each line in the command are a _seperate_ shell environment
     (unless you continue them)


Run:


```sh
make help
```


### Short cuts


```
LOUD = \033[1;34m#
SOFT = \033[0m#


push: ## commit to main
	- echo -en "$(LOUD)Why this push? $(SOFT)" ;  read x ; git commit -am "$$x" ;  git push
	- git status
```


### Reproducaibilityity


```
exp1: ../../moot/optimize/[chmp]*/*.csv
	$(foreach f, $^, (lua kah.lua --comparez $f & ); )


experiment1:; $(MAKE) exp1 | tee ~/tmp/$@.out
```


- Output goes to ~/tmp/experiment1.out (and gets copied to screen along the way)- Note the dependencies with wildcards.
   - This four lines run over dozens of  data sets
      [stored in the subdirectories of ../moot/optimizer/...](https://github.com/timm/moot/tree/master/optimize).
- Note the run in background command "&"
   - These four lines set up dozens of parralle tasks. Brings your computer to its knees (for a while).
    


## Data Processing with `gawk`, `grep`, and `sed`


### Extracting Data with `grep`


```make
filter: dataset/data.txt
	grep "pattern" dataset/data.txt > filtered.txt
```


### Processing with `gawk`


```make
analyze: dataset/data.txt
	gawk '{sum += $$2} END {print "Total:", sum}' dataset/data.txt > summary.txt
```


### Stream Editing with `sed`


```make
transform: dataset/data.txt
	sed 's/old/new/g' dataset/data.txt > transformed.txt
```


## Homework


### What to hand in


A link to a directory in a repo containing all your data and
scripts. And output files `step1.txt`, `step2.txt`, `step3.txt`,
`step4.txt`.


### Details


The file https://github.com/txt/se25/blob/main/docs/data.txt
contains 50-ish paragraphs.


Using Make, clean the file, find the ten most used terms, then
write a new text file, one line per para, showing the frequency counts 
of those most used term in each documents.


For example, in the following, the words


```
challenging,do,key,and,data,example,aspect,engineering,we,
```
seem to have been the most common words. Also,
of those words, `challenging` and `aspect`  appears in para1 once
and `data` appears three times.


```
challenging,do,key,and,data,example,aspect,engineering,we,
1,0,0,0,3,0,1,0,0,
0,1,1,2,1,1,0,0,1,
2,0,1,4,3,2,0,0,0,
0,0,1,1,1,1,2,0,3,
1,1,2,2,1,1,0,2,5,
3,2,1,1,4,0,0,1,1
...
```
Here's a makefile to get you going. You have to write
killstopXXX.awk, a magic piece of scripting at YYY and ZZZ.awk


```make
# Define variables
INPUT = data.txt
CLEANED = cleaned.txt
STOPPED = stop.txt
TOKENS = tokens.txt
FREQS = word_counts.txt
TOP_WORDS = top.txt
TABLE = table.txt


# Run the full pipeline
all: $(TABLE)


# Step 1: Canonicalization (Kill puncation, Lowercase, Remove Punctuation)
$(CLEANED): $(INPUT)
	sed 's/[^a-zA-Z ]//g' $< | tr 'A-Z' 'a-z' > $@


# Step2, remove stop words
# Our stops words are
# (is|the|in|but|can|a|the|is|in|of|to|a|that|it|for|on|with|as|this|was|at|by|an|be|from|or|are)
$(STOPPED) : $(CLEANED)
	gawk -f killstopXXX.awk $< > $@


# Step 2: Report `f word`; i.e. the frequency f of word in all paras
$(FREQS): $(STOPPED)
	cat $< | YYY | sort -nr > $@


# Step 3: Extract Top 20 most frequent words
$(TOP_WORDS): $(FREQS)
	gawk '$$2 && NR <=10 {print $$2}' $< > $@


# Step 4: Generate table of word frequencies per paragraph
$(TABLE): $(CLEANED) $(TOP_WORDS)
	gawk -f ZZZ.awk PASS=1 $(TOP_WORDS) PASS=2 $(CLEANED) > $@


# Cleanup
clean:
	rm -f $(CLEANED) $(TOKENS) $(FREQS) $(TOP_WORDS) $(TABLE)


step1: 
   $(MAKE) clean $(CLEANED); head $(CLEANED)


step2:
   $(MAKE) clean $(STOPPED); head $(STOPPED)


step3:
   $(MAKE) clean $(TOP_WORDS); head $(TOP_WORDS)


step4:
   $(MAKE) clean $(TABLE); head $(TABLE) # | column -s, -t
```


(Aside: your system may not have `column` so that is commented
on on the last line. But if you have `column`, then you get a nice
pretty-print.)


The beauty of all this is that you can test each piece. E.g.
to reset everything and just generate the `cleaned.txt` file:


```
make step1
```


And to test the final thing


```
make step4
```


